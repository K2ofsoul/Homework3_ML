{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c0ced",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install segmentation_models_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f92481",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import segmentation_models_pytorch as smp\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f622777",
   "metadata": {},
   "source": [
    "# 第二部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27ed0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class ETTDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 檢查交集\n",
    "        image_files = {os.path.splitext(f)[0]: f for f in os.listdir(image_dir)}\n",
    "        mask_files = {os.path.splitext(f)[0]: f for f in os.listdir(mask_dir)}\n",
    "        self.filenames = sorted(list(set(image_files.keys()) & set(mask_files.keys())))\n",
    "\n",
    "        if len(self.filenames) == 0:\n",
    "            print(\"找不到圖像與遮罩對應的交集檔案。\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.filenames[idx]\n",
    "        for ext in [\".jpg\", \".png\", \".jpeg\"]:\n",
    "            img_path = os.path.join(self.image_dir, fname + ext)\n",
    "            if os.path.exists(img_path):\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"找不到圖片：{fname} (支援 jpg/png/jpeg)\")\n",
    "\n",
    "        mask_path = os.path.join(self.mask_dir, fname + \".png\")\n",
    "        if not os.path.exists(mask_path):\n",
    "            raise FileNotFoundError(f\"找不到遮罩：{fname}.png\")\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f5e985",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(name):\n",
    "    if name == \"unet\":\n",
    "        return smp.Unet(encoder_name=\"resnet34\", encoder_weights=None, in_channels=3, classes=1)\n",
    "    elif name == \"unetpp\":\n",
    "        return smp.UnetPlusPlus(encoder_name=\"resnet34\", encoder_weights=None, in_channels=3, classes=1)\n",
    "    elif name == \"deeplab\":\n",
    "        model = deeplabv3_resnet50(pretrained=False, num_classes=1)\n",
    "        return model\n",
    "    else:\n",
    "        raise ValueError(\"模型名稱必須為 'unet'、'unetpp' 或 'deeplab'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4db8b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_eval(model_name, base_dir, fold=\"Fold1\", epochs=3, batch_size=4):\n",
    "    print(f\"開始訓練模型：{model_name.upper()}，資料集：{fold}\")\n",
    "    model = get_model(model_name)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # 載入圖片與遮罩資料夾\n",
    "    train_images = os.path.join(base_dir, fold, \"train\")\n",
    "    train_masks  = os.path.join(base_dir, fold, \"trainannot\")\n",
    "    val_images   = os.path.join(base_dir, fold, \"val\")\n",
    "    val_masks    = os.path.join(base_dir, fold, \"valannot\")\n",
    "\n",
    "    train_dataset = ETTDataset(train_images, train_masks, transform)\n",
    "    val_dataset = ETTDataset(val_images, val_masks, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, masks in train_loader:\n",
    "            #images, masks = images.cuda(), masks.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            if isinstance(outputs, dict):  # 對 DeepLabV3 做特別處理\n",
    "              outputs = outputs[\"out\"]\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # 驗證階段\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                #images, masks = images.cuda(), masks.cuda()\n",
    "                outputs = model(images)\n",
    "                if isinstance(outputs, dict):  # 對 DeepLabV3 做特別處理\n",
    "                  outputs = outputs[\"out\"]\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"[{model_name}] Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908f149",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = \"/content\"\n",
    "\n",
    "train_and_eval(\"unet\", base_dir, fold=\"Fold1\")\n",
    "train_and_eval(\"deeplab\", base_dir, fold=\"Fold1\")\n",
    "train_and_eval(\"unetpp\", base_dir, fold=\"Fold1\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
